# ğŸš€ Lokales RAG-System in Kubernetes  
### *Ollama Â· ChromaDB Â· FastAPI Â· Kubernetes Â· Docker*

Dieses Repository enthÃ¤lt eine vollstÃ¤ndige, reproduzierbare **On-Prem KI-Architektur**, mit der ein lokales Retrieval-Augmented-Generation-System (RAG) betrieben werden kann â€” ohne Cloud, ohne externe APIs.

Das System kombiniert:

- **Ollama** â†’ Lokaler LLM-Server (z. B. Llama 3)  
- **ChromaDB** â†’ Moderne Vektordatenbank  
- **FastAPI** â†’ RAG-Backend mit `/ingest` und `/query`  
- **Kubernetes** â†’ Orchestrierung, Networking, Deployment  
- **Docker** â†’ Containerisierung der Anwendung  

Diese Anleitung ist so geschrieben, dass **Auszubildende** oder **Einsteiger:innen** den kompletten Aufbau nachvollziehen kÃ¶nnen und gleichzeitig **professionelle QualitÃ¤t** fÃ¼r erfahrene Techniker bietet.

---

# ğŸ“˜ Inhaltsverzeichnis

1. [Ãœberblick](#-Ã¼berblick)
2. [Architekturdiagramm](#-architekturdiagramm)
3. [Systemkomponenten](#ï¸-systemkomponenten)
4. [Installation & Setup](#-installation--setup)
5. [Deployments](#ï¸-deployments)
6. [End-to-End-Tests](#-end-to-end-tests)
7. [Troubleshooting](#-troubleshooting)
8. [WeiterfÃ¼hrende Dokumentation](#-weiterfÃ¼hrende-dokumentation)
9. [Projekt fÃ¼r Auszubildende](#-projekt-fÃ¼r-auszubildende)

---

# ğŸ§­ Ãœberblick

Dieses Repository zeigt, wie man ein modernes KI-System aufbaut, das:

- **eigene Dokumente speichert**
- **semantisch durchsuchen kann**
- **Fragen mithilfe eines LLM beantwortet**
- **vollstÃ¤ndig lokal und offline funktioniert**

RAG = Retrieval-Augmented Generation  
â†’ Ein LLM erzeugt Antworten **auf Basis externer Dokumente**, nicht nur aus seinem Training.

Dies ist die Architektur, wie sie heute in KI-Projekten in Unternehmen, BehÃ¶rden und Forschung Ã¼blich ist.

---

# ğŸ§  Architekturdiagramm

             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚            Nutzer             â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚  HTTP / API
                             â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚           FastAPI             â”‚
             â”‚         rag-api Backend       â”‚
             â”‚   /ingest     /query          â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ Kontextsuche
                             â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚           ChromaDB            â”‚
             â”‚     Vektordatenbank           â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ Embeddings / Chat
                             â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚             Ollama            â”‚
             â”‚  Lokale LLM + Embeddings      â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
---

# ğŸ§© Systemkomponenten

## ğŸ”¹ **Ollama â€“ Lokaler LLM-Server**
- fÃ¼hrt LLMs lokal aus (z. B. Llama 3, Mistral)  
- erstellt Embeddings (`/api/embeddings`)  
- generiert Antworten (`/api/chat`)  
- arbeitet vollstÃ¤ndig **offline**  

## ğŸ”¹ **ChromaDB â€“ Vektordatenbank**
Speichert Dokumente + Embeddings und ermÃ¶glicht:

- semantische Suche  
- Retrieval fÃ¼r RAG  
- effiziente Kontextfindung  

## ğŸ”¹ **FastAPI (rag-api)**
Das Backend koordiniert:

- `/ingest` â†’ Dokument speichern  
- `/query` â†’ Frage stellen + Kontext holen + LLM antworten lassen  

## ğŸ”¹ **Kubernetes**
Betreibt alle Komponenten zuverlÃ¤ssig:

- Deployments  
- Services  
- Netzwerk  
- Neustart bei AusfÃ¤llen  
- Skalierung  

## ğŸ”¹ **Docker**
Verpackt die Anwendung in portable Images fÃ¼r K8s.

---

# ğŸ›  Installation & Setup

Die komplette Setup-Anleitung findest du hier:

ğŸ“„ **[`docs/K8S_SETUP.md`](docs/K8S_SETUP.md)**

Sie umfasst:

- Installation von Docker  
- Installation von Kubernetes (kubeadm)  
- Netzwerk-Konfiguration (`br_netfilter`, `ip_forward`)  
- Installation von Flannel  
- Cluster-Validierung  

---

# â˜¸ï¸ Deployments

Alle Kubernetes-Manifeste liegen unter:
k8s/
â”œâ”€ namespaces/
â”œâ”€ ollama/
â”œâ”€ chroma/
â””â”€ rag-api/

---

### â–¶ Ollama installieren

```bash
kubectl apply -f k8s/namespaces/llm-namespace.yaml
kubectl apply -f k8s/ollama/ollama-deployment.yaml
kubectl apply -f k8s/ollama/ollama-service.yaml

Dann Modelle laden:

kubectl -n llm exec -it deploy/ollama -- bash
ollama pull llama3:8b
ollama pull nomic-embed-text

ChromaDB deployen

kubectl apply -f k8s/chroma/chroma-deployment.yaml
kubectl apply -f k8s/chroma/chroma-service.yaml

RAG-API deployen

kubectl apply -f k8s/rag-api/rag-api-deployment.yaml
kubectl apply -f k8s/rag-api/rag-api-service.yaml

ğŸ” End-to-End Tests

kubectl -n rag-demo run curl-test --image=curlimages/curl -- sleep 3600
kubectl -n rag-demo exec -it curl-test -- sh

Dokument einfÃ¼gen

curl -X POST http://rag-api:8001/ingest \
  -H "Content-Type: application/json" \
  -d '{"text": "Dies ist ein Testdokument.", "doc_id": "test1"}'

Frage stellen

curl -X POST http://rag-api:8001/query \
  -H "Content-Type: application/json" \
  -d '{"query": "Worum geht es im Dokument?"}'

ğŸ›  Troubleshooting

Siehe:

ğŸ“„ docs/TROUBLESHOOTING.mdï¿¼

Typische Themen:
	â€¢	flannel CrashLoopBackOff
	â€¢	ollama /api/embeddings Fehler
	â€¢	Chroma-Service nicht erreichbar
	â€¢	JSON-Strukturfehler bei FastAPI
	â€¢	ImagePullBackOff

â¸»

ğŸ“š WeiterfÃ¼hrende Dokumentation
	â€¢	Architektur â†’ docs/ARCHITECTURE.mdï¿¼
	â€¢	Kubernetes Setup â†’ docs/K8S_SETUP.mdï¿¼
	â€¢	RAG Grundlagen â†’ docs/RAG_CONCEPTS.mdï¿¼
	â€¢	Troubleshooting â†’ docs/TROUBLESHOOTING.mdï¿¼
	â€¢	Ãœbungen â†’ training/EXERCISES.mdï¿¼
	â€¢	Kompetenz-Check â†’ training/CHECKLIST.mdï¿¼
	â€¢	Projektaufgabe â†’ training/PROJECT_TASK.md